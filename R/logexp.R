#' logistic exposure link function.
#'
#' This is the logistic exposure link to use with glm's in R
#' It is sourced from Ben Bolker's website : https://rpubs.com/bbolker/logregexp
#'
#' @param exposure The length of time. defaults to 1 unit.
#'
#' @examples
#'
#' # Simulate binomial survival data and estimate dsr
#'
#' \dontrun{
#'
#' # create dummy data
#' n.ind<-30 # number of individuals X intervals
#' dsr<-0.9 # simulated daily survival rate
#' expose<-sample(c(1,2,3),n.ind,replace=TRUE) # simulate the exposure interval length
#'
#' Y<-rbinom(n.ind,1,dsr^expose) #observed survival
#'
#' demo.dat<-data.frame(Y=Y,expose=expose)
#'
#'
#' mod<-glm(Y~1,
#'         family=binomial(link=MDChelp::logexp(demo.dat$expose)),
#'         data=demo.dat)
#'
#'
#'  predict.dat<-data.frame(Y=1,expose=1)
#'
#'
#'  predict(mod,predict.dat,type='link',se.fit=TRUE)
#'  # doesn't work with type='response' and 'newdat'
#'
#' }
#' @export
logexp<- function(exposure = 1) {
  ## hack to help with visualization, post-prediction etc etc
  get_exposure <- function() {
    if (exists("..exposure", envir=.GlobalEnv))
      return(get("..exposure", envir=.GlobalEnv))
    exposure
  }
  linkfun <- function(mu) qlogis(mu^(1/get_exposure()))
  ## FIXME: is there some trick we can play here to allow
  ##   evaluation in the context of the 'data' argument?
  linkinv <- function(eta) plogis(eta)^get_exposure()
  logit_mu_eta <- function(eta) {
    ifelse(abs(eta)>30,.Machine$double.eps,
           exp(eta)/(1+exp(eta))^2)
  }
  mu.eta <- function(eta) {
    get_exposure() * plogis(eta)^(get_exposure()-1) *
      logit_mu_eta(eta)
  }
  valideta <- function(eta) TRUE
  link <- paste("logexp(", deparse(substitute(exposure)), ")",
                sep="")
  structure(list(linkfun = linkfun, linkinv = linkinv,
                 mu.eta = mu.eta, valideta = valideta,
                 name = link),
            class = "link-glm")
}




#' A simple survival simulation.
#'
#' Simulate known or apparent survival data via a HMM, with or without interval
#' censoring or right censoring. The base simulation simulates known-fate data,
#' without interval or right censoring.
#'
#' Interval censoring (for logistic exposure or other known-fate designs) is
#' accomplished by including an observation probability. This will inherently
#' lead to right-censoring, but here, the observation at the last time interval
#' can be fixed to 1 and interval censoring is simulated alternatively. Thus,
#' when there is no formal right censoring, all dead individuals are observed
#' dead at least one time.
#'
#' Right censoring is created by providing two probabilities. The first defines
#' the probability any individual will be censored. The second is used in a
#' binomial probability where n_trials is the length of the observation period.
#' While true right censoring can occur at any time, this better simulates more
#' common causes of right censoring, like transmitters failing at the end of
#' battery life.
#'
#' Known-fate data requires individuals are observable in a dead state. When
#' individuals cannot be observed in a dead state and detection is imperfect,
#' apparent survival is the result. The same parameter that generates intervals
#' for known-fate data with perfect detection can be re-purposed as detection
#' probability for an apparent survival simulation with imperfect detection.
#' Individuals that die are no longer observable as dead, and instead are
#' treated as unobservable.
#'
#' @param S.int the interval survival probability
#' @param nind the number of individuals
#' @param ntime the length of the encounter histories
#' @param p.obs  detection probability for imperfect detection
#' @param obs.start TRUE or FALSE, if true, all individuals are observed at time
#'   =1, otherwise. all individuals may not be observed until later in their
#'   encounter history, or not at all before failing. They are not removed from
#'   the data object and must be excluded before use in analysis.
#' @param last.obs TRUE or FALSE. Is the terminal time interval observed.
#'   Typically TRUE in nest survival studies.
#' @param censor.parms a vector of length 2, giving the probability an
#'   individual is censored and the probability defining the time an individual
#'   is censored. The time of censoring is generated by a binomial where the
#'   maximum length of the encounter history is the number of trials and the
#'   second parameter is the probability. The default values prevent any
#'   individual from being censored. Here, censoring is a known event (i.e. a
#'   known transmitter failure, drop, etc.)
#' @param type LOGEXP, KF, CJS or SURV. CJS= A wide matrix of 1,0; apparent
#'   survival. KF= a wide matrix of 1(live), 0(unobserved), and 2(dead); MS HMM
#'   known-fate LOGEXP= a long data frame formatted for logistic exposure; known
#'   fate SURV= a long data frame of entry time, last observation, and if the
#'   observation was censored or an event was observed-suitable for survival
#'   analysis using the survival program.
#' @returns data
#'
#' @import tidyverse
#' @export
surv_sim1<-function(S.int=0.95,
                    nind=10,
                    ntime=10,
                    p.obs=0.5,
                    last.obs=FALSE,
                    obs.start=TRUE,
                    censor.parms=c(0,1),
                    visit.parms=c(1,1),
                    type='RAW'){
  #library(tidyverse)
  S.mat<-matrix(NA,
                nrow=nind,
                ncol=ntime)


  p.mat<-matrix(rbinom(nind*ntime,1,p.obs),
                nrow=nind,
                ncol=ntime)

  ragged.obs(visit.parms[1],visit.parms[2],nind,ntime)->visit.mat

  S.mat[,1]<-1

  for(i in 1:nind){
    for(t in 2:ntime){
      S.mat[i,t]<-rbinom(1,1,S.int)*S.mat[i,t-1]
    }
  }

  S.mat[S.mat==0]<- 2

  if(obs.start==TRUE){
    p.mat[,1]<-1
    visit.mat[,1]<-1
  }

  if(last.obs==TRUE){
    p.mat[,ntime]<-1
    visit.mat[,n.time]<-1
  }



  # set up censoring parameters

  is.censor<-rbinom(nind,1,censor.parms[1])
  censor.time<-rbinom(nind,ntime,censor.parms[2])

  censor.obs<-is.censor*censor.time

  for(i in which(censor.obs>0)){
    p.mat[i,censor.time[i]:ntime]<--1
  }


  obs.mat<-p.mat*S.mat*visit.mat

  ########  Above  generates generic survival and observational data ###########
suppressWarnings({
  first.obs<-apply(obs.mat,1,function(x)min(which(x==1)))

  last.alive<-apply(obs.mat,1,function(x)max(which(x==1)))

  first.cens<-apply(obs.mat,1,function(x)min(which(x < 0)))
  #
  first.dead<-apply(obs.mat,1,function(x)min(which(x==2)))
  #
  first.dead[is.infinite(first.dead)]<-ncol(obs.mat)

  pmin(first.dead,first.cens)->last.obs
})

  ############  Above generates Indexes for nimble/jags, etc.   ###############
  #logexp
  if(type=='LOGEXP'){

    as.data.frame(obs.mat)%>%
      tibble::rownames_to_column(var='id')%>%
      tidyr::pivot_longer(cols=2:(ntime+1),
                          names_to='time',
                          values_to='obs')%>%
      mutate(time=as.numeric(str_remove(time,'V')))%>%
      filter(obs>0)%>%
      group_by(id)%>%
      mutate(#flag=obs*lag(obs),
        exposure=time-lag(time)
      )%>%
      filter(!is.na(exposure),
             (obs==1 |(obs==2 & !duplicated(obs==2))))%>%
      ungroup()%>%
      mutate(obs=ifelse(obs==2,0,1))%>%
      rename(LD=obs)->sim.dat

    return(sim.dat)
  }


  # CJS
  if(type=='CJS'){

    cjs.mat<-obs.mat
    cjs.mat[cjs.mat!=1]<-0

    if(censor.parms[1]!=0){
      warning("censoring in CJS is treated as a non-detect.
              If you wish to include known censoring events in CJS,
              truncate the encounter history for individuals using 'last.obs'")}


    return(list(cjs.mat=cjs.mat,
                first.obs=first.obs,
                last.obs=last.obs))
  }

  # survival object


  if(type=='SURV'){
    as.data.frame(obs.mat)%>%
    tibble::rownames_to_column(var='id')%>%
    tidyr::pivot_longer(cols=2:(ntime+1),
                        names_to='time',
                        values_to='obs')%>%
    mutate(time=as.numeric(str_remove(time,'V')))%>%
    filter(obs!=0)%>%
    group_by(id)%>%
    mutate(#flag=obs*lag(obs),
      exposure=time-lag(time)
    )%>%
    ungroup()->tmp

  tmp%>%
    group_by(id,obs)%>%
    filter(time==min(time)|
             time==max(time))%>%
    group_by(id)%>%
    mutate(start=lag(time),
           end=time,
           event=obs)%>%
    filter(!is.na(start))%>%
    group_by(id,event)%>%
    filter(time==min(time))%>%
    group_by(id)%>%
    mutate(r.censor=case_when(lead(event)==-1~1,
                              last(obs)==1~1,
                              TRUE ~0),
           event=event-1)%>%
    filter(event>=0)%>%
    ungroup()%>%
    select(id,start,end,event,r.censor)->surv.dat

  return(surv.dat)
}

  if(type=='KF'){

    if(censor.parms[1]!=0){
      warning("You included known censoring, censored events are indicated as< 0.
             If you wish to include known censoring events in this data, you
             need to truncate the encounter history for individuals using 'last.obs'")}

    return(list(enc.mat=enc.mat,
                first.obs=first.obs,
                last.obs=last.obs))

  }


  if(type=='RAW'){
    warning("It puts the value in the argument, or else it gets the raw matrices
            (as a list)")

    return(list(obs.mat=obs.mat,
                visit.mat=visit.mat,
                p.mat=p.mat,
                censor.obs=censor.obs,
                first.obs=first.obs,
                last.alive=last.alive,
                last.obs=last.obs
    ))
  }

}


#' Generate a ragged observation matrix.
#'
#' Ragged observation matrix of 1 and 0. Create noise in observations/ visits
#' like nest monitoring, but separate from a detection probability. With a
#' window looking back up to D days, the probability of an observation on day j
#' is visitP^(# of visits within previous D days x 3). This results in a decrease in
#' the probability of a visit if there have been several visits recently, but
#' increases to maxP, if there have not been any.
#'
#' @param maxD the window to look back over. It will end up being close to the
#'   average "window" of non-observations in any individuals encounter history
#' @param nind the number of individuals
#' @param ntime the length of the encounter histories
#' @param visitP  the probability of a visit when no other visits have occurred
#'   within the past D days
#' @returns A matrix of 1 and 0 indicating a visit
#' @keywords internal



ragged.obs<-function(visitP,
                     maxD,
                     nind,
                     ntime){

  matrix(NA,nrow=nind,
         ncol=ntime)->tmp

  matrix(NA,nrow=nind,
         ncol=ntime)->K



  tmp[,1]<-rbinom(nind,1,visitP^maxD)



  for(i in 1:nind){
    for(j in 2:ntime){

      max(1,j-maxD)->low

      K[i,j]<-max(1,sum(tmp[i,low:j-1],na.rm=TRUE),na.rm=TRUE)

      tmp[i,j]<-rbinom(1,1,visitP^(K[i,j]*3))
    }
  }

  return(tmp)

}




