[{"path":"https://tlyons253.github.io/MDChelp/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 MDChelp authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Time To Event and Known-fate (Survival) Analyses","text":"Time--event analysis can broad encompasses variety methods. us probably encounter type data survival analysis tend use examples application, much flexible . ’s core time event data data : known well-defined “origin” time, start time sample (individual) risk event interest happening. quantity interest time event occurs (long X happens) covariates affect time. event must categorical, either Bernoulli variable (live/dead) multinomial (live, dead cause , dead cause B…) must able determine event happened, event happened (.e. known-fate). Ecologists typically encounter survival analysis event interest death, can almost anything. ecology, ’s used model resources selection (First-passage-time1), epidemiology disease dynamics2, breeding ecology. 3 ’s also core space--event model estimating animal density.4 Importantly, event interest doesn’t just need something can occur (like death), TTE framework can accommodate recurring events. Still, ’ll focus application survival analysis since ’s common can use methods folks might familiar provide context. said, within survival analysis, might often feel like ’re talking circles use one method another can functionally accomplish thing (generally GLM analog things). links TTE models (survival analysis) GLMs using logit probit link , TTE analysis models time event occurring, whereas GLMs model “probability ” event occurring. Time explicit TTE, whereas analyses, might include covariate. ’d argue hazard model confusing use, unless really natural logical “origin” time.","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"key-concepts","dir":"Articles","previous_headings":"","what":"Key Concepts","title":"Time To Event and Known-fate (Survival) Analyses","text":"key concepts important understanding TTE analyses relates analyses.","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"censoring-and-truncation","dir":"Articles","previous_headings":"Key Concepts","what":"Censoring and Truncation","title":"Time To Event and Known-fate (Survival) Analyses","text":"Censoring truncation common survival analyses ’ve dealt whether ’ve used TTE analyses GLM (e.g. logistic exposure).","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"interval-censoring","dir":"Articles","previous_headings":"Key Concepts > Censoring and Truncation","what":"Interval Censoring","title":"Time To Event and Known-fate (Survival) Analyses","text":"common method censoring interval censoring. don’t know exact event time, just occurred sometime interval observation. unless checking nests radio-marked individuals every day, interval censored data. fitting GLM logit link, probably dealt interval censoring using logistic exposure link another technique (like cloglog link + offset). familiar Program MARK used known-fate module , concept interval censoring might seem confusing (least) , lose track individual, code interval ‘00’ indicate individual missing, thus, censor time period. refer interval censoring, ’s “interval censoring” mentioned texts regarding TTE survival analyses. ’s accurately called interval truncation DeCesare et.al (20155) give good explanation. ’s artifact Program MARK using model permit interval censoring. even tell use nest-survival module interval censoring. Compare TTE analysis almost analysis ’ll use interval censoring allowed. , need drop observations. animal observed detected dead later , interval censoring handles uncertainty mortality occurred. observe alive later know survived. never encounter dead alive , ’s just right censoring, relying assumption censoring informative. also requires probability detecting individual doesn’t depend fate-probability finding individual went missing , regardless finding dead alive.","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"right-censoring-and-informative-censoring","dir":"Articles","previous_headings":"Key Concepts > Censoring and Truncation","what":"Right Censoring and informative censoring","title":"Time To Event and Known-fate (Survival) Analyses","text":"lose track individual never find (alive dead) haven’t died yet study ends, right-censoring. latter case, ’s called fixed censoring, whereas former, ’s assumed random. , dying doesn’t cause loose track individual. censoring informative (radio transmitters fail destroyed cars/people/predators) survival estimate biased. true regardless analyze data TTE framework logistic regression framework. random (least nearly) doesn’t matter. lose track lot individuals without knowing fate, ’s recommended don’t use approach relies accurately knowing .","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"left-censoring-and-truncation","dir":"Articles","previous_headings":"Key Concepts > Censoring and Truncation","what":"Left Censoring and Truncation","title":"Time To Event and Known-fate (Survival) Analyses","text":"Left censoring doesn’t make sense survival analysis, means event interest occurred individual became part study. nonsense ’s death. Left censoring undoubtedly occurs data sets, nothing can typically , statistically speaking, account . typically data sets truncation. Left-truncation applies individuals observed origin time, experience time wildlife data; individuals survive long enough us capture . Truncation can accommodated (TTE analysis GLM) specify time capture logit model entry time (relative origin). gets hard wrap head around. whole issue left trunction censoring really makes sense really “origin time”, otherwise often just get taught ways avoid deal . Hazard models accommodate left truncation considering interval individual first observed. GLM, generally treat “heterogeneity” deal including appropriate covariate, age--capture, maybe including age time-varying covariate. Clearly doesn’t correct fact might observing individuals age/stage classes. really isn’t statistical approach “fix” -’s sampling issue. ’s generally talk survival estimates specific age-classes stages.","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"methods","dir":"Articles","previous_headings":"","what":"Methods","title":"Time To Event and Known-fate (Survival) Analyses","text":"quick reminder, methods used derive “survival” estimate, even though modeling survival directly (e.g. TTE).","code":""},{"path":[]},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"glm-approaches--logit-link","dir":"Articles","previous_headings":"Methods > Modeling survival vs Hazards","what":"GLM approaches -Logit link","title":"Time To Event and Known-fate (Survival) Analyses","text":"talking survival time-event analysis ’s helpful start talking using GLM estimate survival (mortality) ’s probably folks familiar . first big difference using GLM, ’re modeling probability event occurring interval, long occurs. generally use approach (opposed TTE method), really don’t ability define origin time, typically individuals entering leaving study varying time points / can’t accurately age individuals. approach, data probably table , minimum, rows equal number individuals x number intervals column indicating individual survived died interval (e.g. 1/0). intervals regular equal length can use generic, built-methods estimating survival (e.g. logit link). interested modeling survival function time (age, day year), typically deal using interval-specific covariate. Left truncation can dealt way, interval truncation can handled omitting intervals unable verify status individual (might necessary), right censoring handled implicitly individual longer appearing records. checks irregular intervals, experience trivial amount interval truncation, better accounting variable length time interval using logistic exposure method.","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"kaplan-meier","dir":"Articles","previous_headings":"Methods > Modeling survival vs Hazards","what":"Kaplan-Meier","title":"Time To Event and Known-fate (Survival) Analyses","text":"Kaplan-Meier called non-parametric method quantities describe (cumulative survival, period survival) obtained simple arithmetic : \\[ S_t=\\frac{N_{alive\\ \\ t}}{N_{alive\\ t-1}}\\] ’re using linear model estimate parameters. use discrete covariates, logit model described equivalent Kaplan-Meier estimate. However, logit model gives flexibility, namely types covariates can include. Furthermore, Kaplan-Meier estimates assume interval censoring. ’s generally best bet don’t many individuals data set. Plots Kaplan-Meier estimates typically show cumulative survival probability function time stair-step pattern. Note implying survival probability varies time. Kaplan-Meier estimates survival time step, visualized proportion individuals remaining time T, equivalent \\(S^T\\), \\(S\\) 1-unit survival probability.  can see GLM- constant survival estimates cumulative survival probability lower observed data, end, KM estimate shows. Nevertheless, produce average daily survival rate. GLM allowed time-varying survival better approximation KM curve, also may just overfitting, data plot simulated using constant survival probability.","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"log-log-link","dir":"Articles","previous_headings":"Methods > Modeling survival vs Hazards","what":"Log-Log link","title":"Time To Event and Known-fate (Survival) Analyses","text":"alternative using logit-link regression use log-log link : \\[ S=exp(-exp(X\\beta))\\\\ \\ \\ inverse\\\\ X\\beta=log(-log(S))\\] \\(S\\) survival probability \\(X\\beta\\) linear predictor. approach gives interpretation (hazard ratios) \\(\\beta_k\\) regression coefficients proportional hazard models. Often preferable using logit link hazards ratios (relative difference mortality) don’t change whether model talking weekly, monthly, annual survival. Odds ratios differ, may just confusing worse, misleading. R, use complementary log-log link, equivalent replaceing \\(S\\) \\(M\\), \\(X\\beta\\) predicts. R, still code data 1=alive, 0=dead, essentially modeling 0’s using data structure cloglog link. Interval censoring can accommodated using logit-link using logistic-exposure link, including offset number exposure days interval using cloglog link.","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"modeling-time-to-event","dir":"Articles","previous_headings":"Methods","what":"Modeling time-to-event","title":"Time To Event and Known-fate (Survival) Analyses","text":"name implies, ’re estimating probability event occurs specific interval (like GLM), instead amount time takes event happen. gets discussed modeling process continuous time (TTE) vs. discrete time. Thus, instead calculating probability event occurs interval, TTE estimating number events/deaths “immortal individual” might experience time frame. Coming background modeling nest survival discrete time, big mental flip wrapping head around stopping thinking analyses like graphs DSR instead, thinking graphs show cumulative survival. ’s curve, called survivor function TTE estimating. derivative curve time point \\(h(t)\\) hazard function. math develop survivor function fundamentally different using something like logstic (exposure) regression. using logit link, can develop equivalent information computing product logit-transformed linear predictors \\[ Discrete\\ time ,\\ logit\\ link\\\\S_{n|1}=\\prod_{t=1}^{N}S_t=S_1\\cdot S_2\\cdot S_3...S_n\\\\S_t=\\frac{exp(X\\beta)}{1+exp(X\\beta)}\\]  looks like used proportional hazards model \\[ TTE\\ \\ Continuous\\ Time-Proportional Hazards\\\\S_{1|n}=exp(-\\sum_{t=1}^{N}{exp(X\\beta}))\\] doesn’t look like much different, makes math things easier. Particularly, mentioned , comparing effect covariate outcome different unit initially measured \\(t\\) . also becomes easier model wider nonlinear effects time age survival typically available GLM (e.g. linear, quadratic, cubic…). figure right demonstrates . comes TTE workshop TWS meeting Reno 2019, though data long-term deer survival study northern MN.  textbook definition hazard instantaneous rate mortality. hazard high, mortality high vice versa. TTE focuses estimating timing events regardless actual procedure. simplest form TTE linear model \\[h(t) = \\lambda_0 \\cdot \\lambda_t\\] hazard time \\(t\\), product baseline hazard\\(\\lambda_0\\), covariates \\(\\lambda_t\\)can modeled using log link. \\[ \\lambda_t=exp(\\beta_1X_1+\\beta_2X_2...\\beta_kX_k)\\] particular formulation proportional hazards (PH) model. Proportional hazards models can semi-parametric, don’t try specify distribution baseline hazard, fully parametric . distribution used specify baseline hazard can dramatic effect shape hazard curve whether model still proportional hazards model, now becomes accelerated-failure-time (AFT) model, something else.","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"semi-parametric","dir":"Articles","previous_headings":"Methods > Modeling time-to-event","what":"Semi parametric","title":"Time To Event and Known-fate (Survival) Analyses","text":"semi-parametric hazard model synonymous Cox’s proportional hazard. , however, version proportional hazard model. Cox gets name attached came slick way estimate regression coefficients \\(\\lambda_t\\) without ever estimate \\(\\lambda_0\\), using partial likelihood. People don’t really like trying specify baseline ’s often preferable use approach. However, true Cox’s proportional hazard model doesn’t work interval censoring, applications probably use parametric hazards model. example, interval censoring want use proportional hazard model, actually fit parametric hazard model, using exponential baseline hazard. Important note, like cloglog link, modeling mortality, negative coefficients (log-hazard ratios) mean negative association mortality. ’s also worth noting without specifying kind distribution baseline hazard, can get survivor curve estimating baseline non-parametric methods. hard, using parametric, exponential model equivalent. ’s straightforward just !","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"parametric-hazards","dir":"Articles","previous_headings":"Methods > Modeling time-to-event","what":"Parametric Hazards","title":"Time To Event and Known-fate (Survival) Analyses","text":"Parametric hazards specify distribution baseline hazard. Proportional hazards (PH), proportional odds (PO), accelerated-failure-time (AFT) models types parametric TTE models. difference models : link used model hazard whether hazard changes time. Another way see connections re-write time event model linear function times event, hazard: \\[log(T)=\\beta_0+\\beta_1X_1+\\beta_2X_2...+\\sigma\\epsilon\\] random disturbance term \\(\\epsilon\\) follows distribution. software routines don’t estimate variance \\(\\epsilon\\) hold constant estimate \\(\\sigma\\) scaling parameter instead. described Paul Allison SAS survival book, depending distribution assume \\(\\epsilon\\), corresponding hazard function: \\(\\epsilon\\) extreme-value (exponential distribution) \\(\\sigma\\) fixed one T exponentially distributed gives hazard function: \\[log(h(t))=\\beta_0^*+\\beta_1^*X_1...\\beta_k^*X_k\\] functionally hazard model used Cox’s PH now intercept. exponential model, constant hazard nothing specifically models hazard function time. term function time, AFT model. \\(\\epsilon\\) extreme-value (exponential distribution) \\(\\sigma\\) isn’t fixed 1, T follows Weibull distribution , per SAS survival book: \\[log(h(t))=\\alpha\\log(t)+\\beta_0^*+\\beta_1^*X_1...\\beta_k^*X_k\\] now AFT, depending parameter value \\(\\alpha\\)(see pp. 20-21 SAS survival book). case, \\(\\alpha\\) controls hazard varies across time, ensuring event times T follow Weibull distribution. \\(\\alpha\\) just 0, hazard constant time ’re back exponential distribution. Fun fact, Weibull AFT PH model, ’s form can . ’s , equation , think \\(\\alpha\\log(t)\\) baseline hazard Another way write Weibull hazard can found handout 9 : \\[h(t)=\\lambda p t^{p-1}\\\\ log(h(t))=log(\\lambda)+log(p)+(p-1)log(t)\\\\ log(h(t))=\\alpha\\ log(t) +\\beta_0^*+\\beta_1^*X_1...\\beta_k^*X_k\\] \\(p\\) \\(\\frac{1}{\\sigma}\\) \\(log(T)\\) equation . looks like difference two resources \\(\\alpha \\sim p-1\\) value log(p) seems end \\(\\beta_0\\)? forms include Log logistic \\[h(t)=\\frac{\\lambda p t^{p-1}}{1+\\lambda t^p}\\] gives proportional odds model. AFT models Typically, however, fitting AFT model ’re writing linear model hazard, linear model \\(log(T)\\) coefficients expressed effect survival time, hazard.","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"what-makes-a-model-an-aft-andor-ph","dir":"Articles","previous_headings":"Methods > Modeling time-to-event","what":"What makes a model an AFT and/or PH?","title":"Time To Event and Known-fate (Survival) Analyses","text":"graphs help visually demonstrate , lecture notes found . PH proportional hazards, constant hazard rate. short proportional hazards model assumes hazard ratio doesn’t change time changes. graph hazard two groups time parallel, peak hazard occurring time. AFT, hazard peaks earlier later one group. ’s difference /vs. left/right. meant books/slides say AFT “stretches” time AFT. big difference fit AFT model, code (existing package) put linear model survival time, hazard. anything exponential distribution gets really messy looking hazard scale. can still derive , ’s straight forward write linear model \\(T\\), \\(h(t)\\) AFT models also PH models (e.g. Weibull), aren’t. don’t need . whole value AFT models meet proportional hazards assumption (.e. hazard ratio changes time). Still AFT, need specify baseline distribution T. typically won’t use AFT left truncation-? need data help fit curve/ determine appropriate shape baseline hazard. want risky specify one anyway, hope ’re right, can “predict” outside sample survival times individuals never observed. ’s hard know distribution use baseline hazard (.e. hazard vary time) ’s usually easier turn exponential PH model (technically AFT, constant baseline hazard) throw tricks account temporal variation non-constant hazard ratios (see slides Reno). approach works probably end time, gets complicated (e.g. time-varying coefficients, piecewise exponential model), think feels little “Dr. Moreau” (clearly, Brando’s best film ever)","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"example-nest-survival","dir":"Articles","previous_headings":"","what":"Example: nest survival","title":"Time To Event and Known-fate (Survival) Analyses","text":"shows time-varying survival might incorporated hazards model GLM framework. approach assumes know age nest discovery, nests discovered first day. also assumes check active nests 25th day, day nesting attempt complete. , TTE model doesn’t make sense unless logical origin time.","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"constant-survival","dir":"Articles","previous_headings":"Example: nest survival","what":"Constant survival","title":"Time To Event and Known-fate (Survival) Analyses","text":"Simulate data mean DSR 0.985 nesting period 25 days TTE data look like one realization simulated data. Left date nest discovered, right last day monitored, censor refers nest survived interval. Note nests failed point two rows, one representing interval time nest known alive, another interval nest failed. data formatted use nimble model specified . Table 1. Time event data format nest.id left right censor 1 2 13 1 1 13 14 0 2 1 25 1 3 1 25 1 4 1 25 1 5 8 25 1 6 1 25 1 7 3 16 1 7 16 18 0 8 1 25 1 9 1 16 1 9 16 17 0 10 1 25 1 11 1 3 0 12 3 25 1 Survive” package R otherwise fit Cox proportional hazards model handle interval censoring can’t use . ways specify interval censoring right censoring using survreg function “survival” package fits parametric models, specify exponential distribution, ’s equivalent proportional hazards model. , however, assumes monitoring individuals time origin (.e., left truncation)  GLM Data looks like Table 2. subset GLM survival data nest.id day exposure obs.ld 1 6 4 1 1 7 1 1 1 8 1 1 1 9 1 1 1 10 1 1 1 11 1 1 1 13 2 1 1 14 1 0 2 2 1 1 2 3 1 1 2 4 1 1 2 5 1 1 2 7 2 1 2 9 2 1 2 10 1 1","code":""},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"analysis-using-a-tte-hazards-model","dir":"Articles","previous_headings":"Example: nest survival > Constant survival","what":"Analysis using a TTE hazards model","title":"Time To Event and Known-fate (Survival) Analyses","text":"model parametric model exponential distribution use simple exponential function, baseline hazard constant generally produce hazard ratios Cox PH model doesn’t assume baseline hazard.  gamma parameter needs transformed back survival. , just exponentiate value linear scale (case, just gamma, include terms). isn’t surival probability, ’s mortality probability. true transformation : \\[S=1-exp(\\gamma_0)\\\\ \\\\ S=1-exp(\\gamma_0+\\gamma_1X_1+\\gamma_2X_2...)\\] covariates, \\(\\gamma_k\\) log hazard ratios (equivalent \\(\\beta\\) GLM). means estimated daily survival TTE model 0.984.","code":"library(nimble)  constant.model<-nimble::nimbleCode({  gamma0~dflat()     for (j in 1:records) {     for (k in left[j]:(right[j]-1)) {       UCH[j,k] <- exp(gamma0)     }      S[j] <- exp(-sum(UCH[j,left[j]:(right[j]-1)]))     censored[j] ~ dbern(S[j])   }    for (i in 1:25) { #compute the survival function S0     UCH0[i]<-exp(gamma0)     CH0[i]<-sum(UCH0[1:i]) #sum the unit cumulative hazard to get the cumulative                  #hazard (i.e prob of surviving day 1 to i, or S^2,S^3..S^i     S0[i]<-exp(-CH0[i]) # transform to survival estimate to time i   } })    #define data and constants  nim.const<-list(records=nrow(tte.dat),                 left=tte.dat$left,                 right=tte.dat$right) nim.dat<-list(censored=tte.dat$censor)   #inits  nim.init<-function(){list(   gamma0=runif(1,-3,3) ) }   constant.nimmod<-nimble::nimbleModel(code=constant.model,                                constants=nim.const,                                data=nim.dat,                                inits=nim.init())  constant.nimmod$calculate()  # Check to make sure initial values are good.                               #Should be a real number   constant.config<-nimble::configureMCMC(constant.nimmod)  # now is when you can specify different samplers and monitors constant.config$addMonitors(\"CH0\",\"UCH0\",\"S0\")   constant.build<-nimble::buildMCMC(constant.config)   #compile things  constant.comp<-nimble::compileNimble(constant.nimmod)  constant.mcmc<-nimble::compileNimble(constant.build, project=constant.comp)   samples.constant<-nimble::runMCMC(constant.mcmc,                              niter=5000,                              nburnin = 1000,                              nchains = 3) ##             mean        sd     2.5%       50%     97.5% Rhat n.eff ## gamma0 -4.153043 0.2928866 -4.76659 -4.136809 -3.627007    1  2676"},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"analysis-using-logistic-exposure","dir":"Articles","previous_headings":"Example: nest survival > Constant survival","what":"Analysis using logistic exposure","title":"Time To Event and Known-fate (Survival) Analyses","text":"link function needs GlobalEnvironment. Alternatively, ’s included function MDChelp package using ‘MDChelp::logexp()’","code":"#####   Create the link function # Link function comes from Ben Bolker's page: https://rpubs.com/bbolker/logregexp  logexp <- function(exposure = 1) {   ## hack to help with visualization, post-prediction etc etc   get_exposure <- function() {     if (exists(\"..exposure\", env=.GlobalEnv))       return(get(\"..exposure\", envir=.GlobalEnv))     exposure   }   linkfun <- function(mu) qlogis(mu^(1/get_exposure()))   ## FIXME: is there some trick we can play here to allow   ##   evaluation in the context of the 'data' argument?   linkinv <- function(eta) plogis(eta)^get_exposure()   logit_mu_eta <- function(eta) {     ifelse(abs(eta)>30,.Machine$double.eps,            exp(eta)/(1+exp(eta))^2)   }   mu.eta <- function(eta) {     get_exposure() * plogis(eta)^(get_exposure()-1) *       logit_mu_eta(eta)   }   valideta <- function(eta) TRUE   link <- paste(\"logexp(\", deparse(substitute(exposure)), \")\",                 sep=\"\")   structure(list(linkfun = linkfun, linkinv = linkinv,                  mu.eta = mu.eta, valideta = valideta,                  name = link),             class = \"link-glm\") } ###########   mod.logexp<-glm(obs.ld~1,family=binomial(link=MDChelp::logexp(glm.dat$exposure)),                 data=glm.dat)  broom::tidy(mod.logexp)->parms.logit  parms.logit ## # A tibble: 1 × 5 ##   term        estimate std.error statistic  p.value ##   <chr>          <dbl>     <dbl>     <dbl>    <dbl> ## 1 (Intercept)     4.02     0.280      14.4 1.00e-46 #DSR plogis(parms.logit%>%   pull(estimate))->dsr.logit  dsr.logit ## [1] 0.9824191"},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"analysis-using-the-cloglog-link-and-exposure-time-as-an-offset-","dir":"Articles","previous_headings":"Example: nest survival > Constant survival","what":"Analysis using the cloglog link and exposure time as an offset.","title":"Time To Event and Known-fate (Survival) Analyses","text":"back-transforming, need mean mean “exposure” variable. Now compare among methods See similar one another less 0.005 different data-generating value 0.985? See small effect cumulative survival probability \\((DSR^{24})\\) (24 survival periods survive 25 days), just sampling error. mindful, demure. Table 3. Survival estimate comparison among methods Parameter Hazard Logistic exposure Cloglog + offset() \"Truth\" DSR 0.984 0.982 0.984 0.985 Cumulative survival(25d) 0.684 0.653 0.687 0.696","code":"mod.clog<-glm(obs.ld~1+offset(log(exposure)),               family=binomial(link='cloglog'),               data=glm.dat)   broom::tidy(mod.clog)->parms.clog  parms.clog ## # A tibble: 1 × 5 ##   term        estimate std.error statistic  p.value ##   <chr>          <dbl>     <dbl>     <dbl>    <dbl> ## 1 (Intercept)    0.975    0.0745      13.1 4.36e-39 #calculate mean exposure mu.exp<-glm.dat%>%pull(exposure)%>%mean()  data.frame(parms.clog[1,2]+log(mu.exp))%>%   rename(lp=1)%>%   mutate(dsr=1-exp(-exp(lp)))%>%   pull(dsr)->dsr.clog  round(dsr.clog,digits=3) ## [1] 0.984"},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"survival-as-a-function-of-time","dir":"Articles","previous_headings":"Example: nest survival","what":"Survival as a function of time","title":"Time To Event and Known-fate (Survival) Analyses","text":"mentioned biggest advantage TTE models ease one can model time-varying survival compute cumulative survival probability (parametric models ). time ’ll simulate data increase survival nest age increases. survival probability first interval 0.93 regression coefficent 0.3.","code":"#simulate data library(tidyverse) set.seed(1234)  max.age=25 N=40 age.seq<-seq(0,23,1) mu.s=qlogis(0.93) beta.age=0.3 S<-plogis(mu.s+beta.age*age.seq) cumprod(S)   true.mat<-matrix(NA,nrow=N,ncol=max.age)    true.mat[,1]<-1    for(i in 1:N){    for(t in 2:max.age){            true.mat[i,t]<-true.mat[i,t-1]*rbinom(1,1,S[t-1])    }  }   p.mat<-matrix(rbinom(N*max.age,1,0.35),nrow=N,ncol=max.age) # matrix if nest is observed  #p.mat[,1]<-1 # ensure all individuals observed at time=1  p.mat[,max.age]<-1 #all individuals observed by the end (no right censoring)  true.mat[true.mat==0]<- -1 #assign -1 to dead individuals for later processing ease  obs.mat<-true.mat*p.mat   obs.mat%>%   as.data.frame()%>%   rownames_to_column(var=\"nest.id\")%>%     pivot_longer(cols=2:(max.age+1),                names_to='time',                values_to='obs')%>%   mutate(time=as.numeric(str_remove(time,'V')))%>%   filter(obs!=0)%>%   group_by(nest.id)%>%   filter(!all(obs<1))%>%   mutate(exposure=time-lag(time),          flag=obs*lag(obs))%>%   ungroup()%>%   filter((obs==1 |(obs==-1 & flag==-1)))%>%   select(-flag)%>%   mutate(y=ifelse(obs==-1,0,1))->eh.long    eh.long%>%   select(nest.id,time,y)%>%   group_by(nest.id)%>%   filter(y==0|          time %in% max(time[y==1])|           time %in% min(time[y==1]))%>%   mutate(right=lead(time),          censor=lead(y))%>%   filter(!(is.na(right)))%>%   select(nest.id,left=time,right,censor)->tte.time.dat   eh.long%>%   ungroup()%>%   filter(!is.na(exposure))->glm.time.dat"},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"time-varying-hazards-model","dir":"Articles","previous_headings":"Example: nest survival > Survival as a function of time","what":"Time-varying hazards model","title":"Time To Event and Known-fate (Survival) Analyses","text":"fit time-varying hazards model, fit exponential model , include term account time. method just includes nest age covariate, alternative use (improper) conditional autoregressive model. iCAR model doesn’t try specify kind functional relationship (like linear model), can challenging fit.","code":"library(nimble)  time.model<-nimble::nimbleCode({  gamma0~dflat()   beta~dflat()    for(i in 1:24){   age[i]<-beta*nest.age[i] }   for (j in 1:records) {     for (k in left[j]:(right[j]-1)) {              UCH[j,k] <- exp(gamma0+age[k])     }      S[j] <- exp(-sum(UCH[j,left[j]:(right[j]-1)]))     censored[j] ~ dbern(S[j])   }    for (i in 1:24) { #compute the survival function S0     UCH0[i]<-exp(gamma0+age[i])     CH0[i]<-sum(UCH0[1:i]) #sum the unit cumulative hazard to get the cumulative                  #hazard (i.e prob of surviving day 1 to i, or S^2,S^3..S^i     S0[i]<-exp(-CH0[i]) # transform to survival estimate to time i   } })    #define data and constants  nim.const<-list(records=nrow(tte.time.dat),                 left=tte.time.dat$left,                 right=tte.time.dat$right,                 nest.age=seq(0,23,1)) nim.dat<-list(censored=tte.time.dat$censor)   #inits  nim.init<-function(){list(   gamma0=runif(1,-10,-1),   beta=runif(1,-10,-1)   #S=runif(nrow(tte.time.dat),0.5,0.9),   #UCH=matrix(runif(nrow(tte.time.dat)*25,5,10),nrow=nim.const$records,ncol=25) ) }   time.nimmod<-nimble::nimbleModel(code=time.model,                                constants=nim.const,                                data=nim.dat,                                inits=nim.init())  time.nimmod$calculate()  # Check to make sure initial values are good.                               #Should be a real number time.nimmod$initializeInfo()  time.config<-nimble::configureMCMC(time.nimmod)  # now is when you can specify different samplers and monitors time.config$addMonitors(\"CH0\",\"UCH0\",\"S0\")  time.config$replaceSamplers(target = c('gamma0','beta'),                        type= 'AF_slice')  time.build<-nimble::buildMCMC(time.config)   #compile things  time.comp<-nimble::compileNimble(time.nimmod)  time.mcmc<-nimble::compileNimble(time.build, project=time.comp)   samples.time<-nimble::runMCMC(time.mcmc,                              niter=10000,                              nburnin = 3000,                              nchains = 3) ##        parm          med   dsr.med cumsurv.med ## 1   UCH0[1] 0.0450048247 0.9549952   0.9549952 ## 2   UCH0[2] 0.0347043221 0.9652957   0.9202909 ## 3   UCH0[3] 0.0266844750 0.9733155   0.8936064 ## 23 UCH0[23] 0.0001762815 0.9998237   0.8031316 ## 24 UCH0[24] 0.0001372484 0.9998628   0.8029943 ## 25 UCH0[25] 0.0001070775 0.9998929   0.8028873"},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"analysis-using-logistic-exposure-1","dir":"Articles","previous_headings":"Example: nest survival > Survival as a function of time","what":"Analysis using logistic exposure","title":"Time To Event and Known-fate (Survival) Analyses","text":"","code":"###########    mod.logexp<-glm(y~time,                 family=binomial(                   link=MDChelp::logexp(glm.time.dat$exposure)),                 data=glm.time.dat)  broom::tidy(mod.logexp)->parms.logit    # parms.logit   #DSR parms.logit%>%   pull(estimate)->dsr.logit # round(dsr.logit,digits=3)  age=seq(1,24,1)  dsr.logexp<-plogis(dsr.logit[1]+dsr.logit[2]*age)   # dsr.logexp"},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"analysis-using-the-cloglog-link-and-exposure-time-as-an-offset--1","dir":"Articles","previous_headings":"Example: nest survival > Survival as a function of time","what":"Analysis using the cloglog link and exposure time as an offset.","title":"Time To Event and Known-fate (Survival) Analyses","text":"turns isn’t advisable exposure isn’t roughly . gives biased estimates. think part issue , arises shape cloglog distribution near tails probability. want hazards, just run hazards model.","code":"glm.time.dat$exposure    mod.clog<-glmmTMB::glmmTMB(y~time+exposure,               family=binomial(link='cloglog'),               data=glm.time.dat)  glmmTMB::fixef(mod.clog)$cond->parms.clog  parms.clog  age=seq(1,24,1) median(glm.time.dat$exposure) #offset not included because log(1) (1 exposure day) = 0  lp= parms.clog[1]+parms.clog[2]*age # linear predicator  dsr.clog=1-exp(-exp(lp))  dsr.clog  prod(dsr.clog)"},{"path":"https://tlyons253.github.io/MDChelp/articles/TTE-Advanced.html","id":"state-space-or-hmm-formulation","dir":"Articles","previous_headings":"Example: nest survival > Survival as a function of time","what":"State-space or HMM formulation","title":"Time To Event and Known-fate (Survival) Analyses","text":"last step going equivalent Program MARK . ’s Bayesian don’t reformat data anything like haven’t figured now, ’m kind lazy.  Table 4. Daily survival estimate comparison among methods, (time-varying survival). Model Age 1 Age 2 Age 3 Age 4 Age 5 Age 6 Age 7 Age 8 Age 9 Age 10 Age 11 Age 12 Age 13 Age 14 Age 15 Age 16 Age 17 Age 18 Age 19 Age 20 Age 21 Age 22 Age 23 Age 24 Hazard 0.9550 0.9203 0.8936 0.8732 0.8575 0.8454 0.8361 0.8287 0.8230 0.8185 0.8150 0.8122 0.8101 0.8084 0.8071 0.8061 0.8053 0.8047 0.8042 0.8038 0.8035 0.8033 0.8031 0.8030 Logistic exposure 0.9365 0.9474 0.9565 0.9641 0.9705 0.9757 0.9800 0.9836 0.9865 0.9889 0.9909 0.9926 0.9939 0.9950 0.9959 0.9966 0.9972 0.9977 0.9982 0.9985 0.9988 0.9990 0.9992 0.9993 State Space 0.9622 0.9684 0.9737 0.9781 0.9817 0.9848 0.9874 0.9895 0.9913 0.9928 0.9940 0.9950 0.9959 0.9966 0.9971 0.9976 0.9980 0.9984 0.9986 0.9989 0.9991 0.9992 0.9994 0.9995 \"Truth\" 0.9300 0.9472 0.9603 0.9703 0.9778 0.9835 0.9877 0.9909 0.9932 0.9950 0.9963 0.9972 0.9979 0.9985 0.9989 0.9992 0.9994 0.9995 0.9997 0.9997 0.9998 0.9999 0.9999 0.9999 Table 5. Cumulative survival estimate comparison among methods; (time-varying survival). Parameter Hazard Logistic exposure State Space \"Truth\" 25d survival 0.803 0.695 0.798 0.753 Now fun part. differences daily survival rates among different methods, compared “Truth” (Table 4.) doesn’t seem bad, ’s likely due part, just random sampling error (just one realization truth). point rate change different among three different methods, due underlying distributions (exponential-hazard, modified logistic-logistic exposure, logistic-state space). leads non-trivial differences estimates cumulative survival probability (Table 5.). feature, flaw. Even going back Shaffer 20046, daily survival estimates produced logistic exposure method Program MARK different lead substantially different cumulative survival probabilities. example provided, discrepancy among methods probably also function baseline survival probability quickly increased. might bad , case, DSR never got close 1, increased slowly, started lower, cumulative survival period shorter. ? expected model time-varying survival, probably use hazard state-space formulation. might seem ’s seem agreement, ’s . logistic-exposure framework, covariates assumed constant across exposure period. clearly realistic talking nest age, time-varying covariates can measure even know nest fate corresponding days (daily temperature, daily rainfall, etc.) methods however can, think probably makes little better, across wide range conditions/ parameter values. said, models going wrong, useful whatever works best situation.","code":"##  [1] 0.9621578 0.9684107 0.9736588 0.9780547 0.9817307 0.9848006 0.9873613 ##  [8] 0.9894951 0.9912719 0.9927504 0.9939799 0.9950020 0.9958512 0.9965567 ## [15] 0.9971425 0.9976289 0.9980327 0.9983678 0.9986459 0.9988767 0.9990682 ## [22] 0.9992271 0.9993589 0.9994682 ## [1] 0.7981269"},{"path":"https://tlyons253.github.io/MDChelp/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tim Lyons. Author, maintainer.","code":""},{"path":"https://tlyons253.github.io/MDChelp/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lyons T (2025). MDChelp: Help Environmental Statistical Methods. R package version 0.0.0.9000, https://tlyons253.github.io/MDChelp/, https://github.com/tlyons253/MDChelp.","code":"@Manual{,   title = {MDChelp: Help With Environmental Statistical Methods},   author = {Tim Lyons},   year = {2025},   note = {R package version 0.0.0.9000, https://tlyons253.github.io/MDChelp/},   url = {https://github.com/tlyons253/MDChelp}, }"},{"path":"https://tlyons253.github.io/MDChelp/index.html","id":"mdchelp","dir":"","previous_headings":"","what":"Help With Environmental Statistical Methods","title":"Help With Environmental Statistical Methods","text":"goal MDChelp provide functions demonstrations common statistical methods fish/ wildlife research.","code":""},{"path":"https://tlyons253.github.io/MDChelp/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Help With Environmental Statistical Methods","text":"can install development version MDChelp GitHub :","code":"# install.packages(\"pak\") pak::pak(\"tlyons253/MDChelp\")"},{"path":"https://tlyons253.github.io/MDChelp/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Help With Environmental Statistical Methods","text":"basic example shows solve common problem:","code":"library(MDChelp) ## simulate data and estimate abundance using Chapman's version of a Lincoln-Peterson estimator  LP.sim(500,75,0.3,sample.fixed=TRUE)->sim.dat   chapman(sim.dat$r,         sim.dat$n,         sim.dat$m) #> $N.hat #> [1] 413.069 #>  #> $SE #> [1] 53.71808"},{"path":"https://tlyons253.github.io/MDChelp/reference/LP.sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Lincoln-Petersen Simulation — LP.sim","title":"Lincoln-Petersen Simulation — LP.sim","text":"Simulate data closed, 2-sample mark/recapture study","code":""},{"path":"https://tlyons253.github.io/MDChelp/reference/LP.sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lincoln-Petersen Simulation — LP.sim","text":"","code":"LP.sim(N, mark, recap, sample.fixed = FALSE)"},{"path":"https://tlyons253.github.io/MDChelp/reference/LP.sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lincoln-Petersen Simulation — LP.sim","text":"N Simulated population size mark number individuals marked probability individual caught marked initial sample period. recap probability individual encountered second sample period sample.fixed sample size fixed . TRUE, mark number >1 represents number known marked individuals released, otherwise, probability (0,1)","code":""},{"path":"https://tlyons253.github.io/MDChelp/reference/LP.sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lincoln-Petersen Simulation — LP.sim","text":"list containing: r number individuals marked first sample period n number individuals second sample. m number previously marked individuals second sample.","code":""},{"path":"https://tlyons253.github.io/MDChelp/reference/LP.sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lincoln-Petersen Simulation — LP.sim","text":"","code":"# Two examples if capture is simulated as a fixed number of individuals, or a probability if (FALSE) { # \\dontrun{     LP.sim(N=5E4, mark=300, recap=0.2, sample.fixed=TRUE)->sim1    LP.sim(N=5E4, mark=0.3, recap=0.2, sample.fixed=FALSE)->sim2 } # }"},{"path":"https://tlyons253.github.io/MDChelp/reference/chapman.html","id":null,"dir":"Reference","previous_headings":"","what":"Chapman Estimator for closed populations — chapman","title":"Chapman Estimator for closed populations — chapman","text":"Uses Chapman's modified version Lincoln-Petersen estimator two-sample closed population abundance estimator.","code":""},{"path":"https://tlyons253.github.io/MDChelp/reference/chapman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chapman Estimator for closed populations — chapman","text":"","code":"chapman(r, n, m)"},{"path":"https://tlyons253.github.io/MDChelp/reference/chapman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Chapman Estimator for closed populations — chapman","text":"r number individuals marked initial sample. n total number individuals (marked unmarked) encountered second sample. m number marked individuals encountered second sample","code":""},{"path":"https://tlyons253.github.io/MDChelp/reference/chapman.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Chapman Estimator for closed populations — chapman","text":"list containing: N.hat abundance estimate SE standard error abundance estimate","code":""},{"path":"https://tlyons253.github.io/MDChelp/reference/chapman.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Chapman Estimator for closed populations — chapman","text":"","code":"# Use simulation code to generate data and analyze it if (FALSE) { # \\dontrun{    LP.sim(N=5E4, mark=300, recap=0.2,sample.fixed=TRUE)->sim.dat    chapman(r=sim.dat$r,           n=sim.dat$n,           m=sim.dat$m) } # }"},{"path":"https://tlyons253.github.io/MDChelp/reference/logexp.html","id":null,"dir":"Reference","previous_headings":"","what":"logistic exposure link function. — logexp","title":"logistic exposure link function. — logexp","text":"logistic exposure link use glm's R sourced Ben Bolker's website : https://rpubs.com/bbolker/logregexp","code":""},{"path":"https://tlyons253.github.io/MDChelp/reference/logexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"logistic exposure link function. — logexp","text":"","code":"logexp(exposure = 1)"},{"path":"https://tlyons253.github.io/MDChelp/reference/logexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"logistic exposure link function. — logexp","text":"exposure length time. defaults 1 unit.","code":""},{"path":"https://tlyons253.github.io/MDChelp/reference/logexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"logistic exposure link function. — logexp","text":"","code":"# Simulate binomial survival data and estimate dsr  if (FALSE) { # \\dontrun{  # create dummy data n.ind<-30 # number of individuals X intervals dsr<-0.9 # simulated daily survival rate expose<-sample(c(1,2,3),n.ind,replace=TRUE) # simulate the exposure interval length  Y<-rbinom(n.ind,1,dsr^expose) #observed survival  demo.dat<-data.frame(Y=Y,expose=expose)   mod<-glm(Y~1,         family=binomial(link=MDChelp::logexp(demo.dat$expose)),         data=demo.dat)    predict.dat<-data.frame(Y=1,expose=1)    predict(mod,predict.dat,type='link',se.fit=TRUE)  # doesn't work with type='response' and 'newdat'  } # }"},{"path":"https://tlyons253.github.io/MDChelp/reference/sim1_logexp.html","id":null,"dir":"Reference","previous_headings":"","what":"A simple logistic exposure survival simulation. — sim1_logexp","title":"A simple logistic exposure survival simulation. — sim1_logexp","text":"simulate logistic exposure survival data, returns \"long\" object n.individuals X n observations rows 'wide' object different analysis method. permits right censoring","code":""},{"path":"https://tlyons253.github.io/MDChelp/reference/sim1_logexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A simple logistic exposure survival simulation. — sim1_logexp","text":"","code":"sim1_logexp(   S.int = 0.95,   nind = 10,   ntime = 10,   p.obs = 0.5,   obs.start = TRUE,   r.censor = FALSE,   p.censor = 0.1,   t.censor = 0.8,   cjs = FALSE,   logexp = TRUE )"},{"path":"https://tlyons253.github.io/MDChelp/reference/sim1_logexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A simple logistic exposure survival simulation. — sim1_logexp","text":"S.int interval survival probability nind number individuals ntime length encounter histories p.obs probability create differences exposure period obs.start TRUE FALSE, true, individuals observed time =1, otherwise. individuals may observed later encounter history, failing r.censor TRUE FALSE, probability individual right censored. function defaults individuals observed last time interval (typical nest survival studies) p.censor probability individual right censored time = ntime t.censor controls censoring occurs treating censoring time binomial process number trials length encounter history t.censor probability, resulting number successes interval censoring occurs cjs TRUE, encounter history output matrix typical CJS matrix, suitable use bayesian frameowrk logexp TRUE, returns data frame rows individual observation intervals use glm similar","code":""},{"path":"https://tlyons253.github.io/MDChelp/reference/sim1_logexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A simple logistic exposure survival simulation. — sim1_logexp","text":"logexp = TRUE, data frame nest-visits interval visits separate column.","code":""},{"path":"https://tlyons253.github.io/MDChelp/reference/sim1_logexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A simple logistic exposure survival simulation. — sim1_logexp","text":"","code":"# Show a long-format survival data set using the above defaults if (FALSE) { # \\dontrun{  sim1_logexp(r.censor=TRUE,p.censor=0.2)->sim.dat  } # }"}]
